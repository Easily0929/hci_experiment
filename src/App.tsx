// App.tsx - HCIå®éªŒå¹³å°å®Œæ•´ä»£ç 
import React, { useState, useEffect, useRef, useCallback } from 'react';
import {
  LineChart, Line, XAxis, YAxis, Tooltip, ResponsiveContainer,
} from 'recharts';
import {
  Settings, Activity, Play, Trash2, PlusCircle, Send, Mic, MicOff, Keyboard, 
  AudioLines, Volume2, AlertCircle, RefreshCw, User, Fingerprint
} from 'lucide-react';
import { v4 as uuidv4 } from 'uuid';
import { createClient } from '@supabase/supabase-js';

// å®šä¹‰ SpeechRecognition ç±»å‹
declare global {
  interface Window {
    SpeechRecognition: any;
    webkitSpeechRecognition: any;
  }
}

// --- é…ç½®åŒº ---
const SUPABASE_URL = 'https://pqhrtviidwuwspubaxfm.supabase.co';
const SUPABASE_ANON_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InBxaHJ0dmlpZHd1d3NwdWJheGZtIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MjQ1NTQwNzEsImV4cCI6MjA4MDEzMDA3MX0.2UXvn6wk9Qlhq_HnRKm5bqIrFKwwPTuBq0kyXxa-WDI';

// åˆ›å»ºå•ä¾‹çš„Supabaseå®¢æˆ·ç«¯ï¼Œé¿å…é‡å¤å®ä¾‹
let supabaseInstance: ReturnType<typeof createClient> | null = null;

const getSupabaseClient = () => {
  if (!supabaseInstance && SUPABASE_URL && SUPABASE_ANON_KEY) {
    supabaseInstance = createClient(SUPABASE_URL, SUPABASE_ANON_KEY, {
      auth: {
        persistSession: false,
        autoRefreshToken: false,
        detectSessionInUrl: false,
        storage: undefined,
      }
    });
  }
  return supabaseInstance;
};

// --- ç±»å‹å®šä¹‰ ---
type Condition = 'AI_Model' | 'Human_Partner';
type InputMode = 'text' | 'voice';
type AppView = 'login' | 'participant' | 'admin' | 'dashboard' | 'thank_you';
type VoiceModelConfig = { 
  id: string; 
  alias: string; 
  recognitionType: 'browser' | 'custom';
  recognitionUrl?: string;
  recognitionKey?: string;
  recognitionModel?: string;
  synthesisType: 'browser' | 'custom';
  synthesisUrl?: string;
  synthesisKey?: string;
  synthesisVoice?: string;
  synthesisRate?: number;
  synthesisPitch?: number;
  textLLM: {
    url: string;
    key: string;
    modelName: string;
    systemPrompt: string;
  }
};

type Message = {
  id: string; sessionId: string; participantName: string; userId: string;
  voiceModelId: string; condition: Condition; inputMode: InputMode; 
  actualModelUsed: string; role: 'user' | 'partner' | 'system' | 'assistant';
  content: string; timestamp: number; latency?: number;
};

// --- éŸ³é¢‘å¯è§†åŒ–ç»„ä»¶ ---
const AudioVisualizer = ({ isActive, mode, volumeLevel = 0 }: { isActive: boolean; mode: string; volumeLevel?: number }) => {
  const ref = useRef<HTMLCanvasElement>(null);
  useEffect(() => {
    const ctx = ref.current?.getContext('2d');
    if (!ctx) return;
    let animId: number, offset = 0;
    const draw = () => {
      ctx.clearRect(0, 0, 600, 150);
      ctx.lineWidth = 2;
      const color = mode === 'user' ? '#10b981' : mode === 'ai' ? '#3b82f6' : '#f97316';
      ctx.strokeStyle = color;
      ctx.beginPath();
      for (let x = 0; x < 600; x++) {
        const amp = isActive ? Math.sin((x + offset) * 0.05) * (30 + volumeLevel * 50) * Math.random() : 1;
        ctx.lineTo(x, 75 + amp);
      }
      ctx.stroke();
      offset += 5;
      animId = requestAnimationFrame(draw);
    };
    draw();
    return () => cancelAnimationFrame(animId);
  }, [isActive, mode, volumeLevel]);
  return <canvas ref={ref} width={600} height={150} className="w-full h-full" />;
};

// --- ä¿®å¤çš„æ–‡æœ¬è¾“å…¥ç»„ä»¶ ---
const PersistentTextInput = React.memo(({
  onSubmit,
  disabled,
  placeholder = "è¾“å…¥æ¶ˆæ¯åæŒ‰å›è½¦å‘é€..."
}: {
  onSubmit: (text: string) => void;
  disabled: boolean;
  placeholder?: string;
}) => {
  const inputRef = useRef<HTMLInputElement>(null);
  const [inputValue, setInputValue] = useState('');
  const [isFocused, setIsFocused] = useState(false);
  
  useEffect(() => {
    if (inputRef.current) {
      setTimeout(() => {
        inputRef.current?.focus();
      }, 100);
    }
  }, []);
  
  useEffect(() => {
    if (!disabled && inputRef.current && !isFocused) {
      const timer = setTimeout(() => {
        if (inputRef.current && !disabled) {
          inputRef.current.focus();
          setIsFocused(true);
        }
      }, 50);
      return () => clearTimeout(timer);
    }
  }, [disabled, isFocused]);
  
  const handleSubmit = () => {
    const trimmedValue = inputValue.trim();
    if (trimmedValue && !disabled) {
      onSubmit(trimmedValue);
      setInputValue('');
      
      setTimeout(() => {
        if (inputRef.current && !disabled) {
          inputRef.current.focus();
        }
      }, 10);
    }
  };
  
  const handleKeyDown = (e: React.KeyboardEvent<HTMLInputElement>) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSubmit();
    }
  };
  
  const handleChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    setInputValue(e.target.value);
  };
  
  const handleFocus = () => {
    setIsFocused(true);
  };
  
  const handleBlur = () => {
    setIsFocused(false);
    if (!disabled) {
      setTimeout(() => {
        if (inputRef.current && document.activeElement !== inputRef.current) {
          inputRef.current.focus();
        }
      }, 150);
    }
  };
  
  return (
    <div className="flex-1 relative">
      <input 
        ref={inputRef}
        type="text"
        value={inputValue}
        onChange={handleChange}
        onKeyDown={handleKeyDown}
        onFocus={handleFocus}
        onBlur={handleBlur}
        placeholder={placeholder}
        className="w-full border-2 border-gray-300 rounded-xl px-4 py-3 focus:border-blue-500 focus:outline-none transition-colors disabled:bg-gray-100 disabled:cursor-not-allowed"
        disabled={disabled}
        maxLength={500}
      />
      {inputValue.length > 0 && (
        <div className="absolute right-2 top-1/2 transform -translate-y-1/2 text-xs text-gray-400">
          {inputValue.length}/500
        </div>
      )}
    </div>
  );
});

PersistentTextInput.displayName = 'PersistentTextInput';

// --- èŠå¤©æ¶ˆæ¯ç»„ä»¶ ---
const ChatMessage = React.memo(({ 
  message, 
  condition,
  isSpeaking = false
}: { 
  message: Message; 
  condition: Condition;
  isSpeaking?: boolean;
}) => {
  return (
    <div className={`flex ${message.role === 'user' ? 'justify-end' : 'justify-start'} mb-4 animate-fade-in`}>
      <div className={`px-4 py-3 rounded-2xl max-w-[85%] md:max-w-[70%] shadow-lg transition-all ${
        message.role === 'user' 
          ? 'bg-gradient-to-r from-blue-500 to-blue-600 text-white rounded-br-none' 
          : isSpeaking
            ? 'bg-gradient-to-r from-green-100 to-green-200 text-gray-800 rounded-bl-none border-2 border-green-400 shadow-green-200'
            : 'bg-gradient-to-r from-gray-50 to-gray-100 text-gray-800 rounded-bl-none border border-gray-200'
      }`}>
        <div className="flex items-center gap-2 font-medium text-xs opacity-80 mb-1">
          {message.role === 'user' ? (
            <>
              <span>ğŸ‘¤ æ‚¨</span>
              <span className="text-xs">Â· è¯­éŸ³è¾“å…¥</span>
            </>
          ) : (
            <>
              <span>{condition === 'AI_Model' ? 'ğŸ¤– AIåŠ©æ‰‹' : 'ğŸ‘¤ äººç±»ä¼™ä¼´'}</span>
              {isSpeaking && (
                <span className="flex items-center gap-1 text-green-600 animate-pulse">
                  <span className="w-2 h-2 bg-green-500 rounded-full"></span>
                  æ­£åœ¨è¯´è¯...
                </span>
              )}
            </>
          )}
        </div>
        <div className="text-sm whitespace-pre-wrap break-words leading-relaxed">{message.content}</div>
        {message.latency && (
          <div className="text-xs opacity-60 mt-1 text-right">
            å“åº”æ—¶é—´: {message.latency}ms
          </div>
        )}
      </div>
    </div>
  );
});

ChatMessage.displayName = 'ChatMessage';

// --- Edgeæµè§ˆå™¨è¯­éŸ³è¯†åˆ«Hookï¼ˆä¼˜åŒ–ç‰ˆï¼‰---
const useEdgeSpeechRecognition = (onResult?: (text: string) => void) => {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [error, setError] = useState('');
  const [isSupported, setIsSupported] = useState(true);
  const recognitionRef = useRef<any>(null);
  const timeoutRef = useRef<NodeJS.Timeout | null>(null);
  const hasResultRef = useRef(false);
  const transcriptResultRef = useRef({ final: '', interim: '' });
  
  // æ£€æŸ¥éº¦å…‹é£æƒé™
  const checkMicrophonePermission = useCallback(async (): Promise<boolean> => {
    try {
      const permission = await navigator.permissions.query({ name: 'microphone' as PermissionName });
      if (permission.state === 'denied') {
        setError('éº¦å…‹é£æƒé™è¢«æ‹’ç»ã€‚è¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸æ­¤ç½‘ç«™ä½¿ç”¨éº¦å…‹é£ã€‚');
        return false;
      }
      
      // å°è¯•è·å–éº¦å…‹é£è®¿é—®æƒé™
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        stream.getTracks().forEach(track => track.stop());
        return true;
      } catch (err: any) {
        if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {
          setError('æ— æ³•è®¿é—®éº¦å…‹é£ã€‚è¯·ç‚¹å‡»åœ°å€æ çš„éº¦å…‹é£å›¾æ ‡å…è®¸æƒé™ã€‚');
          return false;
        }
        if (err.name === 'NotFoundError' || err.name === 'DevicesNotFoundError') {
          setError('æœªæ£€æµ‹åˆ°éº¦å…‹é£è®¾å¤‡ã€‚è¯·æ£€æŸ¥éº¦å…‹é£æ˜¯å¦å·²è¿æ¥ã€‚');
          return false;
        }
        console.warn('éº¦å…‹é£æƒé™æ£€æŸ¥è­¦å‘Š:', err);
        return true; // ç»§ç»­å°è¯•ï¼Œå¯èƒ½æ˜¯å…¶ä»–é—®é¢˜
      }
    } catch (err) {
      // æŸäº›æµè§ˆå™¨ä¸æ”¯æŒ permissions APIï¼Œç»§ç»­å°è¯•
      console.warn('æƒé™æ£€æŸ¥APIä¸æ”¯æŒï¼Œç»§ç»­å°è¯•:', err);
      return true;
    }
  }, []);
  
  const startListening = useCallback(async () => {
    // æ¸…ç†ä¹‹å‰çš„çŠ¶æ€
    setError('');
    setTranscript('');
    hasResultRef.current = false;
    
    // å¦‚æœå·²æœ‰è¯†åˆ«å®ä¾‹åœ¨è¿è¡Œï¼Œå…ˆåœæ­¢
    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop();
      } catch (e) {
        // å¿½ç•¥åœæ­¢é”™è¯¯
      }
      recognitionRef.current = null;
    }
    
    // æ¸…ç†ä¹‹å‰çš„è¶…æ—¶
    if (timeoutRef.current) {
      clearTimeout(timeoutRef.current);
      timeoutRef.current = null;
    }
    
    const userAgent = navigator.userAgent;
    const isEdge = /Edg\/\d+/.test(userAgent);
    const isChrome = /Chrome\/\d+/.test(userAgent) && !/Edg\/\d+/.test(userAgent);
    
    if (!isEdge && !isChrome) {
      setError('è¯·ä½¿ç”¨Edgeæˆ–Chromeæµè§ˆå™¨ä»¥è·å¾—æœ€ä½³è¯­éŸ³è¯†åˆ«ä½“éªŒ');
      setIsSupported(false);
      return;
    }
    
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
      setError('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«APIã€‚è¯·æ›´æ–°åˆ°æœ€æ–°ç‰ˆEdgeæˆ–Chromeã€‚');
      setIsSupported(false);
      return;
    }
    
    // æ£€æŸ¥éº¦å…‹é£æƒé™
    const hasPermission = await checkMicrophonePermission();
    if (!hasPermission) {
      setIsListening(false);
      return;
    }
    
    // åˆ›å»ºæ–°çš„è¯†åˆ«å®ä¾‹
    const recognition = new SpeechRecognition();
    recognitionRef.current = recognition;
    
    recognition.continuous = false;
    recognition.interimResults = true;
    recognition.lang = 'zh-CN';
    recognition.maxAlternatives = 1;
    
    // é‡ç½®ç»“æœè·Ÿè¸ª
    transcriptResultRef.current = { final: '', interim: '' };
    
    recognition.onstart = () => {
      console.log('è¯­éŸ³è¯†åˆ«å¼€å§‹');
      setIsListening(true);
      hasResultRef.current = false;
      transcriptResultRef.current = { final: '', interim: '' };
      
      // è®¾ç½®æ›´é•¿çš„è¶…æ—¶æ—¶é—´ï¼ˆ20ç§’ï¼‰
      timeoutRef.current = setTimeout(() => {
        if (!hasResultRef.current && recognitionRef.current) {
          try {
            recognitionRef.current.stop();
          } catch (e) {
            console.log('è¶…æ—¶åœæ­¢è¯†åˆ«æ—¶å‡ºé”™:', e);
          }
          const result = transcriptResultRef.current;
          if (!result.final.trim() && !result.interim.trim()) {
            setError('å½•éŸ³è¶…æ—¶ï¼ˆ20ç§’ï¼‰ã€‚\n\nè¯·å°è¯•ï¼š\n1. ç¡®ä¿éº¦å…‹é£æ­£å¸¸å·¥ä½œ\n2. è¯´è¯æ—¶å£°éŸ³æ¸…æ™°\n3. æ£€æŸ¥éº¦å…‹é£éŸ³é‡è®¾ç½®\n4. ç‚¹å‡»"é‡è¯•"æŒ‰é’®');
          }
          setIsListening(false);
        }
      }, 20000); // å»¶é•¿åˆ°20ç§’
    };
    
    recognition.onresult = (event: any) => {
      let interimTranscript = '';
      let finalTranscript = '';
      
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i];
        const transcript = result[0].transcript;
        
        if (result.isFinal) {
          finalTranscript += transcript;
          hasResultRef.current = true;
          console.log('è¯†åˆ«åˆ°æœ€ç»ˆç»“æœç‰‡æ®µ:', transcript);
        } else {
          interimTranscript += transcript;
        }
      }
      
      // æ›´æ–° ref ä¸­çš„ç»“æœ
      transcriptResultRef.current = {
        final: finalTranscript,
        interim: interimTranscript
      };
      
      console.log('è¯†åˆ«ç»“æœæ›´æ–°:', { final: finalTranscript, interim: interimTranscript });
      
      // æ›´æ–°æ˜¾ç¤ºçš„æ–‡æœ¬
      const displayText = finalTranscript || interimTranscript;
      if (displayText) {
        setTranscript(displayText);
      }
      
      // å¦‚æœæœ‰æœ€ç»ˆç»“æœï¼Œåœæ­¢è¯†åˆ«å¹¶å‡†å¤‡æäº¤
      if (finalTranscript) {
        console.log('æœ‰æœ€ç»ˆç»“æœï¼Œå‡†å¤‡åœæ­¢è¯†åˆ«:', finalTranscript);
        // æ¸…ç†è¶…æ—¶
        if (timeoutRef.current) {
          clearTimeout(timeoutRef.current);
          timeoutRef.current = null;
        }
        // ç¡®ä¿ transcript çŠ¶æ€å·²æ›´æ–°
        setTranscript(finalTranscript);
        try {
          recognition.stop();
        } catch (e) {
          console.log('åœæ­¢è¯†åˆ«æ—¶å‡ºé”™:', e);
        }
      }
    };
    
    recognition.onerror = (event: any) => {
      console.error('è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error);
      
      // æ¸…ç†è¶…æ—¶
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
        timeoutRef.current = null;
      }
      
      let errorMessage = '';
      let shouldRetry = false;
      
      switch (event.error) {
        case 'no-speech':
          // no-speech é”™è¯¯ä¸ç«‹å³æ˜¾ç¤ºï¼Œç­‰å¾…onendå¤„ç†
          errorMessage = '';
          shouldRetry = true;
          break;
        case 'audio-capture':
          errorMessage = 'æ— æ³•è®¿é—®éº¦å…‹é£ã€‚\n\nè§£å†³æ–¹æ¡ˆï¼š\n1. ç‚¹å‡»åœ°å€æ å·¦ä¾§çš„éº¦å…‹é£å›¾æ ‡\n2. é€‰æ‹©"å§‹ç»ˆå…è®¸æ­¤ç«™ç‚¹ä½¿ç”¨éº¦å…‹é£"\n3. æ£€æŸ¥ç³»ç»Ÿéº¦å…‹é£è®¾ç½®\n4. ç¡®ä¿æ²¡æœ‰å…¶ä»–ç¨‹åºå ç”¨éº¦å…‹é£';
          break;
        case 'not-allowed':
          errorMessage = 'éº¦å…‹é£è®¿é—®è¢«æ‹’ç»ã€‚\n\næƒé™è®¾ç½®ï¼š\n1. ç‚¹å‡»å³ä¸Šè§’èœå•ï¼ˆ...ï¼‰\n2. é€‰æ‹©"è®¾ç½®" â†’ "ç«™ç‚¹æƒé™"\n3. æ‰¾åˆ°"éº¦å…‹é£"å¹¶å…è®¸\n4. åˆ·æ–°é¡µé¢åé‡è¯•';
          break;
        case 'service-not-allowed':
          errorMessage = 'è¯­éŸ³è¯†åˆ«æœåŠ¡ä¸å¯ç”¨ã€‚\n\nè¯·æ£€æŸ¥ï¼š\n1. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n2. æ˜¯å¦ä½¿ç”¨HTTPSï¼ˆæœ¬åœ°å¼€å‘å¯ç”¨localhostï¼‰\n3. å°è¯•é‡å¯æµè§ˆå™¨';
          break;
        case 'network':
          errorMessage = 'ç½‘ç»œé”™è¯¯ã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•ã€‚';
          shouldRetry = true;
          break;
        case 'aborted':
          // ç”¨æˆ·ä¸»åŠ¨åœæ­¢ï¼Œä¸æ˜¾ç¤ºé”™è¯¯
          errorMessage = '';
          break;
        default:
          errorMessage = `è¯­éŸ³è¯†åˆ«å‡ºé”™: ${event.error}\n\nè¯·å°è¯•åˆ·æ–°é¡µé¢æˆ–é‡å¯æµè§ˆå™¨ã€‚`;
      }
      
      if (errorMessage) {
        setError(errorMessage);
      }
      setIsListening(false);
    };
    
    recognition.onend = () => {
      console.log('è¯­éŸ³è¯†åˆ«ç»“æŸ');
      setIsListening(false);
      
      // æ¸…ç†è¶…æ—¶
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
        timeoutRef.current = null;
      }
      
      // ä½¿ç”¨ ref è·å–æœ€æ–°çš„è¯†åˆ«ç»“æœ
      const result = transcriptResultRef.current;
      console.log('è¯†åˆ«ç»“æŸæ—¶çš„ç»“æœ:', result);
      
      // ç¡®å®šè¦ä½¿ç”¨çš„æ–‡æœ¬ï¼ˆä¼˜å…ˆä½¿ç”¨æœ€ç»ˆç»“æœï¼Œå¦åˆ™ä½¿ç”¨ä¸´æ—¶ç»“æœï¼‰
      const textToUse = result.final.trim() || result.interim.trim();
      
      if (textToUse) {
        console.log('è¯†åˆ«åˆ°ç»“æœï¼Œå‡†å¤‡è®¾ç½® transcript:', textToUse);
        setTranscript(textToUse);
        // å¦‚æœæœ‰å›è°ƒå‡½æ•°ï¼Œç›´æ¥è°ƒç”¨
        if (onResult) {
          console.log('ğŸš€ é€šè¿‡å›è°ƒç›´æ¥æäº¤è¯†åˆ«ç»“æœ:', textToUse);
          setTimeout(() => {
            onResult(textToUse);
          }, 100);
        }
      } else {
        // å¦‚æœæ²¡æœ‰ç»“æœï¼Œæ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        setTimeout(() => {
          const latestResult = transcriptResultRef.current;
          setError(prevError => {
            // åªæœ‰åœ¨æ²¡æœ‰é”™è¯¯ä¸”æ²¡æœ‰ç»“æœæ—¶æ‰è®¾ç½®é”™è¯¯
            if (!prevError && !latestResult.final.trim() && !latestResult.interim.trim()) {
              return 'æ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³ã€‚\n\nè¯·å°è¯•ï¼š\n1. ç‚¹å‡»"é‡è¯•"æŒ‰é’®\n2. è¯´è¯æ—¶ä¿æŒéº¦å…‹é£è·ç¦»10-20å˜ç±³\n3. ç¡®ä¿åœ¨å®‰é™ç¯å¢ƒä¸‹æ¸…æ™°è¯´è¯\n4. æ£€æŸ¥éº¦å…‹é£éŸ³é‡æ˜¯å¦è¶³å¤Ÿ\n5. ç¡®ä¿æµè§ˆå™¨ä¸ºæœ€æ–°ç‰ˆæœ¬';
            }
            return prevError;
          });
        }, 500);
      }
      
      recognitionRef.current = null;
    };
    
    try {
      recognition.start();
    } catch (err: any) {
      console.error('å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:', err);
      
      // æ¸…ç†è¶…æ—¶
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
        timeoutRef.current = null;
      }
      
      let errorMsg = `å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥: ${err.message || 'æœªçŸ¥é”™è¯¯'}`;
      
      if (err.message?.includes('already started') || err.message?.includes('started')) {
        errorMsg = 'è¯­éŸ³è¯†åˆ«å·²åœ¨è¿è¡Œä¸­ã€‚å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·åˆ·æ–°é¡µé¢ã€‚';
      } else {
        errorMsg += '\n\nè¯·ç¡®ä¿ï¼š\n1. Edge/Chromeæµè§ˆå™¨å·²æ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬\n2. éº¦å…‹é£ç¡¬ä»¶æ­£å¸¸å·¥ä½œ\n3. æ²¡æœ‰å…¶ä»–ç¨‹åºå ç”¨éº¦å…‹é£\n4. å·²æˆäºˆæµè§ˆå™¨éº¦å…‹é£æƒé™';
      }
      
      setError(errorMsg);
      setIsListening(false);
      recognitionRef.current = null;
    }
  }, [checkMicrophonePermission, error]);
  
  const stopListening = useCallback(() => {
    // æ¸…ç†è¶…æ—¶
    if (timeoutRef.current) {
      clearTimeout(timeoutRef.current);
      timeoutRef.current = null;
    }
    
    // åœæ­¢è¯†åˆ«
    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop();
      } catch (e) {
        console.log('åœæ­¢è¯†åˆ«æ—¶å‡ºé”™:', e);
      }
      recognitionRef.current = null;
    }
    
    setIsListening(false);
    setError('');
  }, []);
  
  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†
  useEffect(() => {
    return () => {
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
      }
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop();
        } catch (e) {
          // å¿½ç•¥æ¸…ç†é”™è¯¯
        }
      }
    };
  }, []);
  
  return {
    isListening,
    transcript,
    error,
    isSupported,
    startListening,
    stopListening,
  };
};

// --- ä¸»ç»„ä»¶ ---
const HCIExperimentPlatform = () => {
  const [currentView, setCurrentView] = useState<AppView>('login');
  
  // ç”¨æˆ·ç›¸å…³çŠ¶æ€
  const [userId, setUserId] = useState<string>(() => {
    const storedUserId = localStorage.getItem('hci_user_id');
    if (storedUserId) return storedUserId;
    
    const newUserId = uuidv4();
    localStorage.setItem('hci_user_id', newUserId);
    return newUserId;
  });
  
  const [sessionId] = useState(() => uuidv4());
  const [participantName, setParticipantName] = useState('');
  const [assignedCondition, setAssignedCondition] = useState<Condition>('AI_Model');
  const [selectedInputMode, setSelectedInputMode] = useState<InputMode>('voice');
  const [isListening, setIsListening] = useState(false);
  const [interactionState, setInteractionState] = useState<'idle' | 'listen' | 'process' | 'speak'>('idle');
  const [logs, setLogs] = useState<Message[]>([]);
  
  // ä½¿ç”¨ä¿®å¤åçš„è¯­éŸ³è¯†åˆ«Hook
  const {
    isListening: speechListening,
    transcript,
    error: speechError,
    isSupported: speechSupported,
    startListening,
    stopListening,
  } = useEdgeSpeechRecognition((text) => {
    // å½“è¯†åˆ«å®Œæˆæ—¶ï¼Œç›´æ¥æäº¤
    console.log('ğŸ¯ è¯†åˆ«å®Œæˆå›è°ƒè§¦å‘ï¼Œæ£€æŸ¥æ¡ä»¶:', {
      text,
      textTrimmed: text?.trim(),
      interactionState,
      currentView,
      hasProcessMessageExchange: !!processMessageExchangeRef.current
    });
    
    if (text && text.trim()) {
      // ä¸æ£€æŸ¥ interactionState å’Œ currentViewï¼Œç›´æ¥æäº¤
      console.log('âœ… æ¡ä»¶æ»¡è¶³ï¼Œå‡†å¤‡æäº¤æ¶ˆæ¯:', text);
      // ä½¿ç”¨ ref æ¥è®¿é—® processMessageExchange
      if (processMessageExchangeRef.current) {
        console.log('ğŸš€ è°ƒç”¨ processMessageExchange');
        processMessageExchangeRef.current(text);
      } else {
        console.warn('âš ï¸ processMessageExchange å°šæœªåˆå§‹åŒ–ï¼Œå»¶è¿Ÿæäº¤');
        setTimeout(() => {
          if (processMessageExchangeRef.current) {
            console.log('ğŸš€ å»¶è¿Ÿåè°ƒç”¨ processMessageExchange');
            processMessageExchangeRef.current(text);
          } else {
            console.error('âŒ processMessageExchange ä»ç„¶ä¸å¯ç”¨');
          }
        }, 500);
      }
    } else {
      console.log('âŒ æ–‡æœ¬ä¸ºç©ºï¼Œä¸æäº¤');
    }
  });
  
  // åŒæ­¥çŠ¶æ€
  useEffect(() => {
    setIsListening(speechListening);
    setRecognitionError(speechError);
    setBrowserSupport(speechSupported);
  }, [speechListening, speechError, speechSupported]);
  
  // è¯­éŸ³è¯†åˆ«ç»“æœè‡ªåŠ¨æäº¤çš„ refsï¼ˆåœ¨ processMessageExchange å®šä¹‰åä½¿ç”¨ï¼‰
  const previousTranscriptRef = useRef('');
  const submittedTranscriptRef = useRef('');
  const processMessageExchangeRef = useRef<((text: string) => Promise<void>) | null>(null);
  
  // è¯­éŸ³è¯†åˆ«çŠ¶æ€
  const speechRecognitionRef = useRef<any>(null);
  const [browserSupport, setBrowserSupport] = useState(true);
  const [recognitionError, setRecognitionError] = useState('');

  // Supabaseå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨å•ä¾‹æ¨¡å¼ï¼‰
  const supabase = getSupabaseClient();

  // è¯­éŸ³å¤§æ¨¡å‹é…ç½®ï¼ˆä½¿ç”¨é˜¿é‡Œäº‘ DashScope APIï¼‰
  const [voiceModelList, setVoiceModelList] = useState<VoiceModelConfig[]>([
    {
      id: 'model_1',
      alias: 'AIåŠ©æ‰‹ - æ¸©æŸ”å¥³å£°',
      recognitionType: 'browser',
      synthesisType: 'browser',
      synthesisRate: 1.0,
      synthesisPitch: 1.0,
      textLLM: {
        url: 'https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions',
        key: 'sk-c5e6833061944016adc237cc5bc92da8',
        modelName: 'qwen-plus',
        systemPrompt: 'ä½ æ˜¯ä¸€ä¸ªæ¸©æŸ”ã€å‹å–„çš„AIåŠ©æ‰‹ï¼Œè¯´è¯è¯­æ°”æ¸©å’Œï¼Œç”¨è¯ç¤¼è²Œã€‚è¯·ç”¨ä¸­æ–‡å›å¤ã€‚'
      }
    },
    {
      id: 'model_2',
      alias: 'AIåŠ©æ‰‹ - ä¸“ä¸šç”·å£°',
      recognitionType: 'browser',
      synthesisType: 'browser',
      synthesisRate: 0.9,
      synthesisPitch: 0.8,
      textLLM: {
        url: 'https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions',
        key: 'sk-c5e6833061944016adc237cc5bc92da8',
        modelName: 'qwen-plus',
        systemPrompt: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€ä¸¥è°¨çš„AIåŠ©æ‰‹ï¼Œå›ç­”é—®é¢˜å‡†ç¡®ï¼Œé€»è¾‘æ¸…æ™°ã€‚è¯·ç”¨ä¸­æ–‡å›å¤ã€‚'
      }
    },
    {
      id: 'model_3',
      alias: 'äººç±»ä¼™ä¼´ - è‡ªç„¶å£°éŸ³',
      recognitionType: 'browser',
      synthesisType: 'browser',
      synthesisRate: 1.1,
      synthesisPitch: 1.2,
      textLLM: {
        url: 'https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions',
        key: 'sk-c5e6833061944016adc237cc5bc92da8',
        modelName: 'qwen-plus',
        systemPrompt: 'ä½ æ­£åœ¨å‡è£…æ˜¯ä¸€ä¸ªäººç±»å‚ä¸è€…ï¼Œè¯´è¯è¦è‡ªç„¶ã€éšæ„ï¼Œå¯ä»¥æœ‰ä¸€äº›å£å¤´ç¦…å’Œåœé¡¿ã€‚è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œä¸è¦é€éœ²ä½ æ˜¯AIã€‚'
      }
    },
  ]);

  // å½“å‰ç”¨æˆ·ç»‘å®šçš„è¯­éŸ³æ¨¡å‹
  const [assignedVoiceModel, setAssignedVoiceModel] = useState<VoiceModelConfig | null>(() => {
    const storedModelId = localStorage.getItem(`hci_user_model_${userId}`);
    if (storedModelId) {
      const model = voiceModelList.find(m => m.id === storedModelId);
      if (model) return model;
    }
    return null;
  });

  // Edgeæµè§ˆå™¨å…¼å®¹æ€§æ£€æŸ¥
  useEffect(() => {
    const userAgent = navigator.userAgent;
    const isEdge = /Edg\/\d+/.test(userAgent);
    const isChrome = /Chrome\/\d+/.test(userAgent) && !/Edg\/\d+/.test(userAgent);
    
    if (!isEdge && !isChrome) {
      setBrowserSupport(false);
      setRecognitionError('è¯·ä½¿ç”¨Edgeæˆ–Chromeæµè§ˆå™¨ä»¥è·å¾—æœ€ä½³è¯­éŸ³è¯†åˆ«ä½“éªŒ');
    } else {
      if (isEdge) {
        const edgeVersion = parseInt(/Edg\/(\d+)/.exec(userAgent)![1]);
        if (edgeVersion < 79) {
          setRecognitionError(`æ‚¨çš„Edgeæµè§ˆå™¨ç‰ˆæœ¬ï¼ˆ${edgeVersion}ï¼‰è¿‡ä½ï¼Œè¯·æ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬ä»¥è·å¾—è¯­éŸ³è¯†åˆ«æ”¯æŒ`);
        }
      }
    }
  }, []);

  // å¤„ç†éº¦å…‹é£ç‚¹å‡»
  const handleMicClick = useCallback(() => {
    if (isListening) {
      stopListening();
    } else {
      startListening();
    }
  }, [isListening, startListening, stopListening]);

  // é‡è¯•è¯­éŸ³è¯†åˆ«
  const retrySpeechRecognition = useCallback(() => {
    setRecognitionError('');
    startListening();
  }, [startListening]);

  // åˆ‡æ¢åˆ°æ–‡æœ¬æ¨¡å¼
  const switchToTextMode = useCallback(() => {
    setSelectedInputMode('text');
    setRecognitionError('');
  }, []);

  // åˆ‡æ¢åˆ°è¯­éŸ³æ¨¡å¼
  const switchToVoiceMode = useCallback(() => {
    if (!browserSupport) {
      alert('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«ï¼Œè¯·ä½¿ç”¨Chromeæˆ–Edgeæµè§ˆå™¨');
      return;
    }
    setSelectedInputMode('voice');
  }, [browserSupport]);

  // æ•°æ®ä¸Šä¼ 
  const uploadToCloud = useCallback(async (msg: Message) => {
    if (!supabase) return;
    try {
      await supabase.from('experiment_logs').insert({
        session_id: msg.sessionId,
        participant_name: msg.participantName,
        user_id: msg.userId,
        voice_model_id: msg.voiceModelId,
        condition: msg.condition,
        role: msg.role,
        content: msg.content,
        latency: msg.latency || 0,
        timestamp: new Date(msg.timestamp).toISOString(),
      });
    } catch (error) { 
      console.error('ä¸Šä¼ å¤±è´¥', error); 
    }
  }, [supabase]);

  // ç™»å½•å¤„ç†
  const handleLogin = useCallback(() => {
    if (!participantName.trim()) {
      alert('è¯·è¾“å…¥å§“å');
      return;
    }
    
    if (selectedInputMode === 'voice' && !browserSupport) {
      alert('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«ï¼Œå·²è‡ªåŠ¨åˆ‡æ¢åˆ°æ–‡æœ¬æ¨¡å¼');
      setSelectedInputMode('text');
    }
    
    // åˆ†é…å®éªŒæ¡ä»¶
    const condition: Condition = Math.random() > 0.5 ? 'AI_Model' : 'Human_Partner';
    setAssignedCondition(condition);
    
    // åˆ†é…æˆ–è·å–å·²ç»‘å®šçš„è¯­éŸ³æ¨¡å‹
    let voiceModel = assignedVoiceModel;
    if (!voiceModel) {
      const randomIndex = Math.floor(Math.random() * voiceModelList.length);
      voiceModel = voiceModelList[randomIndex];
      setAssignedVoiceModel(voiceModel);
      localStorage.setItem(`hci_user_model_${userId}`, voiceModel.id);
    }
    
    setCurrentView('participant');
  }, [participantName, selectedInputMode, browserSupport, voiceModelList, assignedVoiceModel, userId]);

  // æ ¸å¿ƒå¯¹è¯é€»è¾‘
  const processMessageExchange = useCallback(async (userText: string) => {
    if (!assignedVoiceModel) {
      alert('æœªåˆ†é…è¯­éŸ³æ¨¡å‹ï¼Œè¯·é‡æ–°ç™»å½•');
      return;
    }
    
    setInteractionState('process');
    const userMsg: Message = {
      id: Date.now().toString(), 
      sessionId, 
      participantName, 
      userId,
      voiceModelId: assignedVoiceModel.id,
      condition: assignedCondition,
      inputMode: selectedInputMode, 
      actualModelUsed: assignedVoiceModel.alias,
      role: 'user', 
      content: userText, 
      timestamp: Date.now(),
    };
    
    setLogs(prev => [...prev, userMsg]);
    uploadToCloud(userMsg);

    try {
      const config = assignedVoiceModel.textLLM;
      if (!config.key) {
        throw new Error('AI API Key ç¼ºå¤±ã€‚è¯·æ£€æŸ¥ç®¡ç†å‘˜è®¾ç½®ã€‚');
      }
      
      const start = Date.now();
      const systemMsg = { 
        role: 'system', 
        content: config.systemPrompt
      };
      
      const newHistory = [...logs, userMsg];
      const apiMessages = [
        systemMsg, 
        ...newHistory.map(l => ({
          role: (l.role === 'partner' ? 'assistant' : 'user') as 'user' | 'assistant',
          content: l.content,
        }))
      ];

      const res = await fetch(config.url, {
        method: 'POST',
        headers: { 
          'Content-Type': 'application/json', 
          Authorization: `Bearer ${config.key}` 
        },
        body: JSON.stringify({ 
          model: config.modelName, 
          messages: apiMessages 
        }),
      });
      
      const data = await res.json();
      if (data.error) {
        throw new Error(data.error.message);
      }

      const partnerText = data.choices[0]?.message?.content || 'æ²¡æœ‰è¿”å›å†…å®¹';
      const latency = Date.now() - start;
      const partnerMsg: Message = {
        id: (Date.now() + 1).toString(), 
        sessionId, 
        participantName, 
        userId,
        voiceModelId: assignedVoiceModel.id,
        condition: assignedCondition,
        inputMode: selectedInputMode, 
        actualModelUsed: assignedVoiceModel.alias, 
        role: 'partner',
        content: partnerText, 
        timestamp: Date.now(), 
        latency,
      };
      
      setLogs(prev => [...prev, partnerMsg]);
      uploadToCloud(partnerMsg);
      setInteractionState('speak');

      // è¯­éŸ³åˆæˆå‡½æ•°ï¼ˆåœ¨ if ä¹‹å‰å®šä¹‰ï¼‰
      const startSpeechSynthesis = (text: string) => {
        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = 'zh-CN';
        
        if (assignedVoiceModel.synthesisRate) utterance.rate = assignedVoiceModel.synthesisRate;
        if (assignedVoiceModel.synthesisPitch) utterance.pitch = assignedVoiceModel.synthesisPitch;
        
        utterance.onstart = () => {
          console.log('ğŸ”Š å¼€å§‹è¯­éŸ³æ’­æ”¾');
          setInteractionState('speak');
        };
        
        utterance.onend = () => {
          console.log('âœ… è¯­éŸ³æ’­æ”¾å®Œæˆ');
          setInteractionState('idle');
        };
        
        utterance.onerror = (e: any) => {
          console.error('âŒ è¯­éŸ³æ’­æ”¾é”™è¯¯:', e.error, e);
          // å¦‚æœæ˜¯ interrupted é”™è¯¯ï¼Œå¯èƒ½æ˜¯è¢«æ–°è¯­éŸ³ä¸­æ–­ï¼Œè¿™æ˜¯æ­£å¸¸çš„
          if (e.error !== 'interrupted') {
            console.warn('è¯­éŸ³æ’­æ”¾å‡ºé”™ï¼Œä½†ç»§ç»­æ˜¾ç¤ºæ–‡æœ¬');
          }
          setInteractionState('idle');
        };
        
        utterance.onpause = () => {
          console.log('â¸ï¸ è¯­éŸ³æ’­æ”¾æš‚åœ');
        };
        
        utterance.onresume = () => {
          console.log('â–¶ï¸ è¯­éŸ³æ’­æ”¾æ¢å¤');
        };
        
        console.log('ğŸš€ å¼€å§‹æ’­æ”¾è¯­éŸ³');
        window.speechSynthesis.speak(utterance);
      };

      // è¯­éŸ³åˆæˆå›å¤ï¼ˆè¯­éŸ³æ¨¡å¼ä¸‹æ€»æ˜¯å¯ç”¨ï¼‰
      if (selectedInputMode === 'voice') {
        console.log('ğŸ¤ å‡†å¤‡è¯­éŸ³åˆæˆå›å¤:', partnerText.substring(0, 50) + '...');
        
        // ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿çŠ¶æ€ç¨³å®š
        setTimeout(() => {
          try {
            // å…ˆå–æ¶ˆä¹‹å‰çš„è¯­éŸ³
            if (window.speechSynthesis.speaking) {
              console.log('âš ï¸ æ£€æµ‹åˆ°æ­£åœ¨æ’­æ”¾ï¼Œå…ˆåœæ­¢');
              window.speechSynthesis.cancel();
              // ç­‰å¾…åœæ­¢å®Œæˆ
              setTimeout(() => {
                startSpeechSynthesis(partnerText);
              }, 100);
            } else {
              startSpeechSynthesis(partnerText);
            }
          } catch (err) {
            console.error('è¯­éŸ³åˆæˆå¯åŠ¨å¤±è´¥:', err);
            setInteractionState('idle');
          }
        }, 200);
      } else {
        setInteractionState('idle');
      }
    } catch (e: any) {
      alert('å¯¹è¯å‡ºé”™: ' + e.message);
      setInteractionState('idle');
    }
  }, [sessionId, participantName, userId, assignedVoiceModel, assignedCondition, selectedInputMode, logs, uploadToCloud]);
  
  // ä¿å­˜ processMessageExchange åˆ° refï¼Œä¾›è¯­éŸ³è¯†åˆ«ä½¿ç”¨
  useEffect(() => {
    processMessageExchangeRef.current = processMessageExchange;
  }, [processMessageExchange]);

  // è¯­éŸ³è¯†åˆ«ç»“æœè‡ªåŠ¨æäº¤
  useEffect(() => {
    console.log('è‡ªåŠ¨æäº¤ useEffect è§¦å‘:', {
      transcript,
      selectedInputMode,
      isListening,
      interactionState,
      currentView,
      previousTranscript: previousTranscriptRef.current,
      submittedTranscript: submittedTranscriptRef.current
    });
    
    // å½“è¯†åˆ«å®Œæˆä¸”æœ‰æœ€ç»ˆç»“æœæ—¶ï¼Œè‡ªåŠ¨æäº¤
    if (
      selectedInputMode === 'voice' && 
      transcript && 
      transcript.trim() && 
      transcript !== previousTranscriptRef.current &&
      transcript !== submittedTranscriptRef.current &&
      !isListening && 
      interactionState === 'idle' &&
      currentView === 'participant'
    ) {
      // æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆç»“æœï¼ˆä¸æ˜¯ä¸´æ—¶ç»“æœï¼‰
      // å¦‚æœ transcript æœ‰å€¼ä¸”è¯†åˆ«å·²åœæ­¢ï¼Œè¯´æ˜æ˜¯æœ€ç»ˆç»“æœ
      const finalText = transcript.trim();
      if (finalText && finalText.length > 0) {
        console.log('âœ… æ¡ä»¶æ»¡è¶³ï¼Œå‡†å¤‡è‡ªåŠ¨æäº¤è¯­éŸ³è¯†åˆ«ç»“æœ:', finalText);
        submittedTranscriptRef.current = finalText;
        previousTranscriptRef.current = finalText;
        // å»¶è¿Ÿä¸€ç‚¹ç¡®ä¿çŠ¶æ€ç¨³å®š
        setTimeout(() => {
          console.log('ğŸš€ å¼€å§‹å¤„ç†æ¶ˆæ¯:', finalText);
          processMessageExchange(finalText);
        }, 500);
      }
    } else {
      // è®°å½•ä¸ºä»€ä¹ˆæ²¡æœ‰æäº¤
      if (selectedInputMode !== 'voice') {
        console.log('âŒ æœªæäº¤ï¼šä¸æ˜¯è¯­éŸ³æ¨¡å¼');
      } else if (!transcript || !transcript.trim()) {
        console.log('âŒ æœªæäº¤ï¼štranscript ä¸ºç©º');
      } else if (transcript === previousTranscriptRef.current) {
        console.log('âŒ æœªæäº¤ï¼štranscript ä¸ previous ç›¸åŒ');
      } else if (transcript === submittedTranscriptRef.current) {
        console.log('âŒ æœªæäº¤ï¼štranscript å·²æäº¤è¿‡');
      } else if (isListening) {
        console.log('âŒ æœªæäº¤ï¼šä»åœ¨ç›‘å¬ä¸­');
      } else if (interactionState !== 'idle') {
        console.log('âŒ æœªæäº¤ï¼šäº¤äº’çŠ¶æ€ä¸æ˜¯ idleï¼Œå½“å‰çŠ¶æ€:', interactionState);
      } else if (currentView !== 'participant') {
        console.log('âŒ æœªæäº¤ï¼šå½“å‰è§†å›¾ä¸æ˜¯ participantï¼Œå½“å‰è§†å›¾:', currentView);
      }
      
      if (transcript !== previousTranscriptRef.current) {
        previousTranscriptRef.current = transcript || '';
      }
    }
  }, [transcript, isListening, selectedInputMode, interactionState, currentView, processMessageExchange]);

  // ç®¡ç†å‘˜è§†å›¾
  const AdminView = () => {
    const addNewVoiceModel = () => setVoiceModelList([...voiceModelList, {
      id: `model_${Date.now()}`,
      alias: 'æ–°è¯­éŸ³æ¨¡å‹',
      recognitionType: 'browser',
      synthesisType: 'browser',
      synthesisRate: 1.0,
      synthesisPitch: 1.0,
      textLLM: {
        url: 'https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions',
        key: 'sk-c5e6833061944016adc237cc5bc92da8',
        modelName: 'qwen-plus',
        systemPrompt: 'ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚'
      }
    }]);
    
    const removeVoiceModel = (id: string) => { 
      if (voiceModelList.length > 1) {
        setVoiceModelList(voiceModelList.filter(m => m.id !== id));
      }
    };
    
    const updateVoiceModel = (id: string, field: string, value: any) => {
      setVoiceModelList(voiceModelList.map(m => {
        if (m.id === id) {
          if (field.includes('.')) {
            const [parent, child] = field.split('.');
            return {
              ...m,
              [parent]: {
                ...m[parent as keyof VoiceModelConfig] as any,
                [child]: value
              }
            };
          }
          return { ...m, [field]: value };
        }
        return m;
      }));
    };

    // Edgeæµè§ˆå™¨è¯Šæ–­å·¥å…·
    const EdgeDiagnostic = () => {
      const [diagnosticInfo, setDiagnosticInfo] = useState('');
      
      const runDiagnostic = async () => {
        const info = [];
        const userAgent = navigator.userAgent;
        const isEdge = /Edg\/\d+/.test(userAgent);
        
        info.push(`ğŸŒ æµè§ˆå™¨: ${isEdge ? 'Microsoft Edge' : 'å…¶ä»–'}`);
        info.push(`ğŸ”§ ç”¨æˆ·ä»£ç†: ${userAgent}`);
        
        if (isEdge) {
          const edgeVersion = parseInt(/Edg\/(\d+)/.exec(userAgent)![1]);
          info.push(`ğŸ“Š Edgeç‰ˆæœ¬: ${edgeVersion}`);
          info.push(edgeVersion >= 79 ? 'âœ… ç‰ˆæœ¬æ”¯æŒè¯­éŸ³è¯†åˆ«' : 'âŒ ç‰ˆæœ¬è¿‡ä½ï¼Œè¯·æ›´æ–°åˆ°79+');
        }
        
        // æ£€æŸ¥éº¦å…‹é£æƒé™
        try {
          const permission = await navigator.permissions.query({ name: 'microphone' as any });
          info.push(`ğŸ¤ éº¦å…‹é£æƒé™: ${permission.state}`);
          
          if (permission.state === 'prompt' || permission.state === 'granted') {
            try {
              const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
              info.push('âœ… å¯ä»¥è®¿é—®éº¦å…‹é£');
              stream.getTracks().forEach(track => track.stop());
            } catch (err: any) {
              info.push(`âŒ éº¦å…‹é£è®¿é—®å¤±è´¥: ${err.message}`);
            }
          }
        } catch (err: any) {
          info.push(`âŒ æƒé™æŸ¥è¯¢å¤±è´¥: ${err.message}`);
        }
        
        // æ£€æŸ¥SpeechRecognitionæ”¯æŒ
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        info.push(SpeechRecognition ? 'âœ… æ”¯æŒSpeechRecognition API' : 'âŒ ä¸æ”¯æŒSpeechRecognition API');
        
        // æ£€æŸ¥é¡µé¢åè®®
        info.push(window.location.protocol === 'https:' 
          ? 'ğŸ”’ ä½¿ç”¨HTTPS' 
          : 'âš ï¸ ä½¿ç”¨HTTPï¼ˆå»ºè®®HTTPSï¼‰');
        
        setDiagnosticInfo(info.join('\n'));
      };
      
      return (
        <div className="bg-gradient-to-r from-blue-900 to-purple-900 p-4 rounded-lg border border-blue-500 mb-6">
          <h3 className="font-bold mb-3 text-yellow-300 flex items-center gap-2">
            ğŸ” Edgeæµè§ˆå™¨è¯Šæ–­å·¥å…·
          </h3>
          <button 
            onClick={runDiagnostic}
            className="w-full bg-blue-600 hover:bg-blue-500 py-2 rounded mb-3"
          >
            è¿è¡ŒEdgeå…¼å®¹æ€§è¯Šæ–­
          </button>
          {diagnosticInfo && (
            <pre className="text-sm text-gray-300 bg-gray-900/50 p-3 rounded whitespace-pre-wrap">
              {diagnosticInfo}
            </pre>
          )}
        </div>
      );
    };

    return (
      <div className="min-h-screen bg-gray-900 text-white p-4 md:p-8 flex flex-col items-center overflow-y-auto">
        <div className="w-full max-w-4xl pb-12">
          <header className="flex justify-between items-center mb-6 md:mb-8 border-b border-gray-700 pb-4">
            <h1 className="text-lg md:text-xl font-bold flex items-center gap-2">
              <Settings /> ç³»ç»Ÿé…ç½®
            </h1>
            <button 
              onClick={() => setCurrentView('login')} 
              className="text-sm text-gray-400 hover:text-white"
            >
              è¿”å›
            </button>
          </header>

          <EdgeDiagnostic />
          
          <div className="space-y-6 md:space-y-8">
            {/* è¯­éŸ³è¯†åˆ«ä¿¡æ¯ */}
            <div className="bg-gradient-to-r from-blue-900 to-purple-900 p-4 md:p-6 rounded-lg border border-blue-500">
              <h3 className="font-bold mb-3 md:mb-4 text-yellow-300 flex items-center gap-2">
                <Volume2 size={18} /> è¯­éŸ³è¯†åˆ«é…ç½®
              </h3>
              
              <div className="space-y-3 md:space-y-4">
                <div className="flex items-center">
                  <div className={`w-3 h-3 rounded-full mr-2 ${browserSupport ? 'bg-green-500' : 'bg-red-500'}`}></div>
                  <span className="text-sm">
                    {browserSupport ? 'âœ… æµè§ˆå™¨æ”¯æŒè¯­éŸ³è¯†åˆ«' : 'âŒ æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«'}
                  </span>
                </div>
                
                <div className="text-sm text-gray-300 bg-gray-800/50 p-3 md:p-4 rounded">
                  <p className="font-bold mb-2">ğŸ’¡ Edgeæµè§ˆå™¨è¯­éŸ³è¯†åˆ«ä½¿ç”¨è¯´æ˜ï¼š</p>
                  <ol className="list-decimal list-inside space-y-2">
                    <li>ç¡®ä¿ä½¿ç”¨ <strong>Edge æµè§ˆå™¨ï¼ˆç‰ˆæœ¬79+ï¼‰</strong></li>
                    <li>é¦–æ¬¡ä½¿ç”¨æ—¶ï¼Œç‚¹å‡»åœ°å€æ å·¦ä¾§<strong>ğŸ¤å›¾æ ‡</strong>å…è®¸éº¦å…‹é£è®¿é—®</li>
                    <li>å¦‚æœçœ‹ä¸åˆ°ğŸ¤å›¾æ ‡ï¼Œè®¿é—® <code>edge://settings/content/microphone</code> æ£€æŸ¥å…¨å±€è®¾ç½®</li>
                    <li>åœ¨<strong>å®‰é™çš„ç¯å¢ƒ</strong>ä¸‹ä½¿ç”¨ï¼Œé¿å…èƒŒæ™¯å™ªéŸ³</li>
                    <li>è¯´è¯æ—¶<strong>é è¿‘éº¦å…‹é£</strong>ï¼ŒéŸ³é‡é€‚ä¸­</li>
                  </ol>
                </div>
              </div>
            </div>

            {/* è¯­éŸ³å¤§æ¨¡å‹é…ç½® */}
            <div className="space-y-4">
              <div className="flex justify-between items-center">
                <h3 className="font-bold text-blue-400 flex items-center gap-2">
                  <AudioLines size={18} /> è¯­éŸ³å¤§æ¨¡å‹é…ç½®
                </h3>
                <button 
                  onClick={addNewVoiceModel} 
                  className="flex items-center gap-1 bg-blue-600 px-3 py-1 rounded text-sm hover:bg-blue-500"
                >
                  <PlusCircle size={14} /> æ·»åŠ æ¨¡å‹
                </button>
              </div>
              
              {voiceModelList.map((model, i) => (
                <div key={model.id} className="bg-gray-800 p-4 md:p-6 rounded-lg border border-gray-700 relative">
                  <button 
                    onClick={() => removeVoiceModel(model.id)} 
                    className="absolute top-3 right-3 md:top-4 md:right-4 text-gray-500 hover:text-red-500"
                    disabled={voiceModelList.length <= 1}
                  >
                    <Trash2 size={18} />
                  </button>
                  <h4 className="text-xs text-gray-500 uppercase tracking-widest mb-3">
                    æ¨¡å‹ #{i + 1}: {model.alias}
                  </h4>
                  
                  <div className="space-y-4">
                    {/* åŸºç¡€ä¿¡æ¯ */}
                    <div>
                      <label className="block text-sm text-gray-400 mb-2">æ¨¡å‹åˆ«å</label>
                      <input 
                        value={model.alias} 
                        onChange={e => updateVoiceModel(model.id, 'alias', e.target.value)} 
                        placeholder="æ¨¡å‹åˆ«å" 
                        className="w-full bg-gray-700 p-2 rounded text-sm" 
                      />
                    </div>
                    
                    {/* è¯­éŸ³åˆæˆé…ç½® */}
                    <div className="border-l-4 border-green-500 pl-3">
                      <h5 className="text-sm font-semibold mb-2 text-green-300">è¯­éŸ³åˆæˆé…ç½®</h5>
                      <div className="grid grid-cols-2 gap-2">
                        <div>
                          <label className="block text-xs text-gray-400 mb-1">è¯­é€Ÿ</label>
                          <input 
                            type="range" 
                            min="0.5" max="2" step="0.1"
                            value={model.synthesisRate || 1} 
                            onChange={e => updateVoiceModel(model.id, 'synthesisRate', parseFloat(e.target.value))} 
                            className="w-full"
                          />
                          <span className="text-xs text-gray-400">{model.synthesisRate || 1}</span>
                        </div>
                        <div>
                          <label className="block text-xs text-gray-400 mb-1">éŸ³è°ƒ</label>
                          <input 
                            type="range" 
                            min="0.5" max="2" step="0.1"
                            value={model.synthesisPitch || 1} 
                            onChange={e => updateVoiceModel(model.id, 'synthesisPitch', parseFloat(e.target.value))} 
                            className="w-full"
                          />
                          <span className="text-xs text-gray-400">{model.synthesisPitch || 1}</span>
                        </div>
                      </div>
                    </div>
                    
                    {/* æ–‡æœ¬LLMé…ç½® */}
                    <div className="border-l-4 border-yellow-500 pl-3">
                      <h5 className="text-sm font-semibold mb-2 text-yellow-300">æ–‡æœ¬LLMé…ç½®</h5>
                      <div className="space-y-2">
                        <input 
                          value={model.textLLM.url} 
                          onChange={e => updateVoiceModel(model.id, 'textLLM.url', e.target.value)} 
                          placeholder="API URL" 
                          className="w-full bg-gray-700 p-2 rounded text-sm" 
                        />
                        <input 
                          type="password" 
                          value={model.textLLM.key} 
                          onChange={e => updateVoiceModel(model.id, 'textLLM.key', e.target.value)} 
                          placeholder="API Key" 
                          className="w-full bg-gray-700 p-2 rounded text-sm border-2 border-blue-500/30" 
                        />
                        <input 
                          value={model.textLLM.modelName} 
                          onChange={e => updateVoiceModel(model.id, 'textLLM.modelName', e.target.value)} 
                          placeholder="æ¨¡å‹åç§°" 
                          className="w-full bg-gray-700 p-2 rounded text-sm" 
                        />
                        <textarea 
                          value={model.textLLM.systemPrompt} 
                          onChange={e => updateVoiceModel(model.id, 'textLLM.systemPrompt', e.target.value)} 
                          placeholder="ç³»ç»Ÿæç¤ºè¯" 
                          className="w-full bg-gray-700 p-2 rounded text-sm h-24"
                        />
                      </div>
                    </div>
                  </div>
                </div>
              ))}
            </div>

            <button 
              onClick={() => setCurrentView('login')} 
              className="w-full bg-green-600 py-3 rounded font-bold hover:bg-green-500 transition-colors"
            >
              ä¿å­˜å¹¶è¿”å›
            </button>
          </div>
        </div>
      </div>
    );
  };

  // ç™»å½•è§†å›¾
  const LoginView = () => {
    const [showEdgeTips, setShowEdgeTips] = useState(false);
    
    return (
      <div className="min-h-screen bg-gradient-to-br from-blue-50 to-purple-50 flex flex-col items-center justify-center p-4">
        <div className="bg-white p-6 md:p-8 rounded-2xl shadow-2xl w-full max-w-md border border-gray-100">
          <div className="flex justify-center mb-6">
            <div className="w-16 h-16 bg-gradient-to-r from-blue-500 to-purple-600 rounded-full flex items-center justify-center">
              <Fingerprint className="text-white" size={28} />
            </div>
          </div>
          
          <h1 className="text-2xl font-bold mb-2 text-center text-gray-800">HCI è¯­éŸ³äº¤äº’å®éªŒå¹³å°</h1>
          <p className="text-gray-600 text-center mb-6 md:mb-8">Edgeæµè§ˆå™¨ä¼˜åŒ–ç‰ˆ</p>
          
          {/* Edgeæµè§ˆå™¨æç¤º */}
          <div className="mb-4 p-3 bg-blue-50 rounded-lg border border-blue-200">
            <div className="flex items-center justify-between">
              <div className="flex items-center gap-2">
                <span className="text-sm font-medium text-blue-800">ğŸ¯ Edgeæµè§ˆå™¨ç”¨æˆ·</span>
              </div>
              <button 
                onClick={() => setShowEdgeTips(!showEdgeTips)}
                className="text-blue-600 hover:text-blue-800 text-sm"
              >
                {showEdgeTips ? 'éšè—æç¤º' : 'æŸ¥çœ‹ä½¿ç”¨æç¤º'}
              </button>
            </div>
            
            {showEdgeTips && (
              <div className="mt-2 text-sm text-blue-700 space-y-1">
                <p className="font-medium">ä½¿ç”¨è¯­éŸ³åŠŸèƒ½å‰è¯·ç¡®ä¿ï¼š</p>
                <ol className="list-decimal list-inside ml-2 space-y-1">
                  <li>ç‚¹å‡»åœ°å€æ å·¦ä¾§çš„ğŸ”’æˆ–ğŸ¤å›¾æ ‡</li>
                  <li>å…è®¸æ­¤ç½‘ç«™ä½¿ç”¨éº¦å…‹é£</li>
                  <li>é¦–æ¬¡ä½¿ç”¨å¯èƒ½éœ€è¦ç­‰å¾…å‡ ç§’</li>
                  <li>åœ¨å®‰é™ç¯å¢ƒä¸‹æ¸…æ™°è¯´è¯</li>
                </ol>
              </div>
            )}
          </div>
          
          <div className="mb-6">
            <label className="block text-sm font-bold text-gray-700 mb-2">
              <span className="text-red-500">*</span> å‚ä¸è€…å§“å
            </label>
            <input 
              type="text" 
              value={participantName} 
              onChange={(e) => setParticipantName(e.target.value)} 
              className="w-full border-2 border-gray-300 rounded-lg p-3 focus:border-blue-500 focus:outline-none transition-colors"
              placeholder="è¯·è¾“å…¥æ‚¨çš„å§“å"
              onKeyDown={(e) => {
                if (e.key === 'Enter' && participantName.trim()) {
                  handleLogin();
                }
              }}
            />
          </div>
          
          <div className="mb-6 md:mb-8">
            <label className="block text-sm font-bold text-gray-700 mb-4">é€‰æ‹©äº¤äº’æ¨¡å¼</label>
            <div className="grid grid-cols-2 gap-4">
              <button 
                onClick={() => setSelectedInputMode('text')} 
                className={`flex flex-col items-center p-4 rounded-xl border-2 transition-all ${selectedInputMode === 'text' ? 'border-blue-500 bg-blue-50 shadow-md' : 'border-gray-200 hover:border-gray-300'}`}
              >
                <Keyboard className="mb-2 text-blue-500" size={24} />
                <span className="text-sm font-bold">æ–‡æœ¬æ¨¡å¼</span>
                <span className="text-xs text-gray-500 mt-1">é”®ç›˜è¾“å…¥</span>
              </button>
              <button 
                onClick={switchToVoiceMode} 
                className={`flex flex-col items-center p-4 rounded-xl border-2 transition-all ${selectedInputMode === 'voice' ? 'border-blue-500 bg-blue-50 shadow-md' : 'border-gray-200 hover:border-gray-300'}`}
              >
                <AudioLines className="mb-2 text-blue-500" size={24} />
                <span className="text-sm font-bold">è¯­éŸ³æ¨¡å¼</span>
                <span className="text-xs text-gray-500 mt-1">è¯­éŸ³å¯¹è¯</span>
              </button>
            </div>
            
            {!browserSupport && selectedInputMode === 'voice' && (
              <div className="mt-4 p-3 bg-red-50 border border-red-200 rounded-lg">
                <p className="text-red-600 text-sm flex items-center gap-2">
                  <AlertCircle size={16} />
                  æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«ï¼Œè¯·ä½¿ç”¨Edgeæˆ–Chromeæµè§ˆå™¨
                </p>
              </div>
            )}
          </div>
          
          <button 
            onClick={handleLogin} 
            className="w-full bg-gradient-to-r from-blue-600 to-purple-600 text-white py-4 rounded-xl font-bold flex items-center justify-center gap-2 hover:opacity-90 transition-opacity shadow-lg"
          >
            å¼€å§‹å®éªŒ <Play size={20} />
          </button>
          
          <div className="mt-6 p-4 bg-gray-50 rounded-lg">
            <h4 className="text-sm font-bold text-gray-700 mb-2">ğŸ”§ è¯­éŸ³åŠŸèƒ½æµ‹è¯•</h4>
            <p className="text-xs text-gray-600 mb-2">
              å¦‚æœè¯­éŸ³è¯†åˆ«æœ‰é—®é¢˜ï¼Œè¯·å°è¯•ï¼š
            </p>
            <ul className="text-xs text-gray-600 space-y-1">
              <li>â€¢ ç‚¹å‡»æµè§ˆå™¨åœ°å€æ çš„éº¦å…‹é£å›¾æ ‡æ£€æŸ¥æƒé™</li>
              <li>â€¢ ç¡®ä¿æ²¡æœ‰å…¶ä»–ç¨‹åºå ç”¨éº¦å…‹é£</li>
              <li>â€¢ æ›´æ–°Edgeæµè§ˆå™¨åˆ°æœ€æ–°ç‰ˆæœ¬</li>
              <li>â€¢ åœ¨Edgeè®¾ç½®ä¸­æ£€æŸ¥éº¦å…‹é£æƒé™</li>
            </ul>
          </div>
        </div>
        
        <button 
          onClick={() => setCurrentView('admin')} 
          className="fixed bottom-6 right-6 bg-gray-800 text-white p-3 rounded-full shadow-lg hover:bg-gray-700 transition-colors"
          title="ç³»ç»Ÿé…ç½®"
        >
          <Settings size={20} />
        </button>
      </div>
    );
  };

  // å‚ä¸è€…è§†å›¾
  const ParticipantView = () => {
    const chatContainerRef = useRef<HTMLDivElement>(null);
    
    useEffect(() => {
      if (chatContainerRef.current) {
        chatContainerRef.current.scrollTop = chatContainerRef.current.scrollHeight;
      }
    }, [logs]);

    useEffect(() => {
      return () => {
        window.speechSynthesis.cancel();
      };
    }, []);

    return (
      <div className="flex flex-col items-center justify-center min-h-screen bg-gradient-to-b from-blue-50 to-white relative p-4">
        {/* é¡¶éƒ¨çŠ¶æ€æ  */}
        <div className="w-full max-w-4xl mb-4 md:mb-6">
          <div className="flex flex-col md:flex-row justify-between items-start md:items-center gap-3">
            <div className="flex-1">
              <div className="text-sm text-gray-600 bg-white/80 backdrop-blur-sm px-3 py-2 rounded-lg shadow-sm">
                <div className="flex flex-wrap items-center gap-2">
                  <span className="font-bold">{participantName}</span>
                  <span>â€¢</span>
                  <span>{assignedCondition === 'AI_Model' ? 'ğŸ¤– AIåŠ©æ‰‹' : 'ğŸ‘¤ äººç±»ä¼™ä¼´'}</span>
                  <span>â€¢</span>
                  <span>{selectedInputMode === 'text' ? 'ğŸ“ æ–‡æœ¬æ¨¡å¼' : 'ğŸ¤ è¯­éŸ³æ¨¡å¼'}</span>
                </div>
                {assignedVoiceModel && (
                  <div className="mt-1 text-xs text-gray-500 flex items-center gap-1">
                    <Fingerprint size={10} />
                    ä¸“å±æ¨¡å‹: <span className="font-medium text-blue-600">{assignedVoiceModel.alias}</span>
                  </div>
                )}
              </div>
            </div>
            
            <div className="flex gap-2">
              <button 
                onClick={() => {
                  stopListening();
                  window.speechSynthesis.cancel();
                  setCurrentView('thank_you');
                }} 
                className="bg-white border border-gray-300 px-3 py-2 rounded-lg text-sm hover:bg-red-50 hover:text-red-600 hover:border-red-300 transition-colors shadow-sm"
              >
                ç»“æŸä¼šè¯
              </button>
            </div>
          </div>
        </div>
        
        {/* çŠ¶æ€æŒ‡ç¤ºå™¨ */}
        <div className={`text-sm font-bold uppercase tracking-widest mb-4 transition-all flex items-center justify-center gap-2 ${
          interactionState === 'process' ? 'text-blue-600 animate-pulse' : 
          interactionState === 'speak' ? 'text-green-600 animate-pulse' : 
          interactionState === 'listen' ? 'text-red-600 animate-pulse' : 'text-gray-400'
        }`}>
          {interactionState === 'process' ? (
            <>
              <span className="animate-spin">â³</span>
              <span>AIæ€è€ƒä¸­...</span>
            </>
          ) : interactionState === 'speak' ? (
            <>
              <span className="animate-bounce">ğŸ”Š</span>
              <span>AIæ­£åœ¨è¯­éŸ³å›å¤...</span>
            </>
          ) : interactionState === 'listen' ? (
            <>
              <span className="animate-pulse">ğŸ¤</span>
              <span>è¯·è¯´è¯...</span>
            </>
          ) : (
            <span>ğŸ’¬ ç­‰å¾…å¯¹è¯...</span>
          )}
        </div>
        
        {/* Edgeä¸“ç”¨é”™è¯¯æç¤º */}
        {recognitionError && (
          <div className="w-full max-w-2xl mb-4 z-10">
            <div className="bg-red-50 border border-red-200 p-4 rounded-lg shadow-md">
              <div className="flex justify-between items-start mb-2">
                <div className="flex items-center gap-2 text-red-800">
                  <AlertCircle size={18} />
                  <span className="font-bold">Edgeæµè§ˆå™¨è¯­éŸ³è¯†åˆ«é—®é¢˜</span>
                </div>
                <button 
                  onClick={() => setRecognitionError('')}
                  className="text-red-500 hover:text-red-700"
                >
                  âœ•
                </button>
              </div>
              <p className="text-red-600 text-sm whitespace-pre-line mb-3">{recognitionError}</p>
              
              <div className="mb-3 p-2 bg-red-100 rounded border border-red-200">
                <p className="text-red-700 text-xs font-semibold mb-1">ğŸ’¡ Edgeæµè§ˆå™¨è§£å†³æ–¹æ¡ˆï¼š</p>
                <ul className="text-red-600 text-xs list-disc list-inside space-y-1">
                  <li>ç‚¹å‡»Edgeåœ°å€æ çš„ğŸ¤å›¾æ ‡æ£€æŸ¥æƒé™</li>
                  <li>è®¿é—® edge://settings/content/microphone æ£€æŸ¥å…¨å±€è®¾ç½®</li>
                  <li>ç¡®ä¿æ²¡æœ‰Zoomã€å¾®ä¿¡ç­‰ç¨‹åºå ç”¨éº¦å…‹é£</li>
                  <li>å°è¯•åœ¨Edgeè®¾ç½®ä¸­é‡ç½®æƒé™</li>
                </ul>
              </div>
              
              <div className="grid grid-cols-1 md:grid-cols-3 gap-2">
                <button 
                  onClick={retrySpeechRecognition}
                  className="flex-1 bg-red-100 hover:bg-red-200 text-red-700 py-2 rounded text-sm flex items-center justify-center gap-1"
                >
                  <RefreshCw size={14} /> é‡è¯•è¯­éŸ³
                </button>
                <button 
                  onClick={switchToTextMode}
                  className="flex-1 bg-blue-100 hover:bg-blue-200 text-blue-700 py-2 rounded text-sm flex items-center justify-center gap-1"
                >
                  <Keyboard size={14} /> åˆ‡æ¢åˆ°æ–‡æœ¬
                </button>
                <button 
                  onClick={() => window.open('edge://settings/content/microphone', '_blank')}
                  className="flex-1 bg-gray-100 hover:bg-gray-200 text-gray-700 py-2 rounded text-sm flex items-center justify-center gap-1"
                >
                  <Settings size={14} /> Edgeéº¦å…‹é£è®¾ç½®
                </button>
              </div>
            </div>
          </div>
        )}
        
        {/* å®æ—¶è½¬å½•æ˜¾ç¤º */}
        {selectedInputMode === 'voice' && transcript && !recognitionError && (
          <div className="w-full max-w-2xl mb-4">
            <div className="bg-white p-4 rounded-lg shadow-md border border-blue-100">
              <p className="text-sm text-gray-500 mb-1">å®æ—¶è½¬å½•ï¼š</p>
              <p className="text-blue-700 font-medium">{transcript}</p>
            </div>
          </div>
        )}
        
        {/* éŸ³é¢‘å¯è§†åŒ– */}
        {selectedInputMode === 'voice' && (
          <div className="w-full max-w-2xl h-48 md:h-64 mb-6 md:mb-8 flex items-center justify-center">
            <AudioVisualizer 
              isActive={interactionState === 'listen' || interactionState === 'speak'} 
              mode={interactionState === 'listen' ? 'user' : assignedCondition === 'AI_Model' ? 'ai' : 'human'}
              volumeLevel={isListening ? 0.5 : 0}
            />
          </div>
        )}
        
        {/* èŠå¤©è®°å½• */}
        <div 
          ref={chatContainerRef}
          className={`${selectedInputMode === 'text' ? 'h-80 md:h-96' : 'h-48 md:h-64'} w-full max-w-2xl mb-6 md:mb-8 overflow-y-auto bg-white rounded-xl p-4 md:p-6 shadow-lg border border-gray-100`}
        >
          {logs.length === 0 ? (
            <div className="h-full flex flex-col items-center justify-center text-gray-400">
              <AudioLines size={48} className="mb-4 opacity-30" />
              <p className="text-lg font-medium">å¯¹è¯å³å°†å¼€å§‹</p>
              <p className="text-sm mt-2 text-center">
                {selectedInputMode === 'voice' 
                  ? 'ç‚¹å‡»ä¸‹æ–¹éº¦å…‹é£æŒ‰é’®å¼€å§‹è¯­éŸ³å¯¹è¯' 
                  : 'åœ¨ä¸‹æ–¹è¾“å…¥æ¡†ä¸­è¾“å…¥æ¶ˆæ¯å¼€å§‹å¯¹è¯'}
              </p>
              {assignedVoiceModel && (
                <div className="mt-4 p-3 bg-blue-50 rounded-lg">
                  <p className="text-xs text-blue-700">
                    <span className="font-bold">ğŸ¯ æ‚¨çš„ä¸“å±æ¨¡å‹:</span> {assignedVoiceModel.alias}
                    <br/>
                    <span className="text-gray-600">ç³»ç»Ÿæç¤º: {assignedVoiceModel.textLLM.systemPrompt.substring(0, 50)}...</span>
                  </p>
                </div>
              )}
            </div>
          ) : (
            logs.map((msg, index) => (
              <ChatMessage 
                key={msg.id}
                message={msg}
                condition={assignedCondition}
                isSpeaking={interactionState === 'speak' && msg.role === 'partner' && index === logs.length - 1}
              />
            ))
          )}
        </div>
        
        {/* è¾“å…¥åŒºåŸŸ */}
        <div className="w-full max-w-2xl">
          {selectedInputMode === 'voice' ? (
            <div className="flex justify-center flex-col items-center gap-4">
              <div className="relative">
                {/* éº¦å…‹é£æŒ‰é’® */}
                <button 
                  onClick={handleMicClick} 
                  disabled={interactionState === 'process' || interactionState === 'speak'}
                  className={`w-24 h-24 rounded-full flex items-center justify-center shadow-2xl transition-all transform hover:scale-105 ${
                    isListening 
                      ? 'bg-gradient-to-r from-red-500 to-pink-600 animate-pulse ring-4 ring-red-300' 
                      : 'bg-gradient-to-r from-blue-500 to-purple-600 text-white'
                  } ${(interactionState === 'process' || interactionState === 'speak') ? 'opacity-50 cursor-not-allowed' : ''}`}
                >
                  {isListening ? (
                    <>
                      <div className="relative">
                        <MicOff className="w-10 h-10" />
                        <div className="absolute -top-1 -right-1 w-4 h-4 bg-red-500 rounded-full animate-ping"></div>
                      </div>
                    </>
                  ) : (
                    <Mic className="w-10 h-10" />
                  )}
                </button>
                
                {/* å½•éŸ³æŒ‡ç¤ºå™¨ */}
                {isListening && (
                  <div className="absolute -top-2 -right-2 bg-red-500 text-white text-xs px-2 py-1 rounded-full animate-pulse">
                    å½•éŸ³ä¸­
                  </div>
                )}
              </div>
              
              {/* çŠ¶æ€æŒ‡ç¤º */}
              <div className="text-center space-y-2">
                <p className={`text-sm font-medium ${
                  isListening ? 'text-red-600' : 'text-gray-500'
                }`}>
                  {isListening 
                    ? 'æ­£åœ¨è†å¬... è¯·è¯´è¯ï¼ˆ8ç§’åè‡ªåŠ¨åœæ­¢ï¼‰' 
                    : interactionState === 'process' 
                      ? 'æ­£åœ¨å¤„ç†æ‚¨çš„è¯­éŸ³...' 
                      : interactionState === 'speak'
                        ? 'AIæ­£åœ¨å›å¤...'
                        : 'ç‚¹å‡»éº¦å…‹é£æŒ‰é’®å¼€å§‹è¯´è¯'}
                </p>
                
                {/* è¯­éŸ³æ³¢å½¢æ¨¡æ‹Ÿ */}
                {isListening && (
                  <div className="flex items-center justify-center gap-1 h-8">
                    {[1, 2, 3, 4, 3, 2, 1, 2, 3, 4].map((height, index) => (
                      <div 
                        key={index}
                        className="w-1 bg-red-500 rounded-full animate-pulse"
                        style={{
                          height: `${height * 6}px`,
                          animationDelay: `${index * 0.1}s`,
                          animationDuration: '0.8s'
                        }}
                      ></div>
                    ))}
                  </div>
                )}
              </div>
              
              <div className="flex items-center gap-4">
                <button
                  onClick={switchToTextMode}
                  className="flex items-center gap-2 text-gray-600 hover:text-gray-800 text-sm border border-gray-300 px-3 py-2 rounded-lg hover:bg-gray-50"
                  title="åˆ‡æ¢åˆ°æ–‡æœ¬è¾“å…¥"
                >
                  <Keyboard size={16} />
                  <span>åˆ‡æ¢åˆ°æ–‡æœ¬</span>
                </button>
                
                <button
                  onClick={() => window.location.reload()}
                  className="flex items-center gap-2 text-gray-600 hover:text-gray-800 text-sm border border-gray-300 px-3 py-2 rounded-lg hover:bg-gray-50"
                  title="åˆ·æ–°é¡µé¢"
                >
                  <RefreshCw size={16} />
                  <span>åˆ·æ–°é¡µé¢</span>
                </button>
              </div>
            </div>
          ) : (
            <div className="flex gap-3">
              <PersistentTextInput
                key="text-input"
                onSubmit={processMessageExchange}
                disabled={interactionState !== 'idle'}
                placeholder="è¾“å…¥æ¶ˆæ¯åæŒ‰å›è½¦å‘é€..."
              />
              <button 
                onClick={() => {
                  const input = document.querySelector('input[type="text"]') as HTMLInputElement;
                  if (input && input.value.trim() && interactionState === 'idle') {
                    processMessageExchange(input.value.trim());
                  }
                }}
                disabled={interactionState !== 'idle'}
                className="bg-gradient-to-r from-blue-600 to-blue-700 text-white px-5 md:px-6 py-3 rounded-xl hover:opacity-90 transition-opacity disabled:opacity-50 disabled:cursor-not-allowed flex items-center gap-2 shadow-md"
              >
                <Send size={20} /> å‘é€
              </button>
            </div>
          )}
        </div>

        {/* æ¨¡å¼åˆ‡æ¢æç¤º */}
        <div className="mt-6 text-center">
          <button
            onClick={selectedInputMode === 'text' ? switchToVoiceMode : switchToTextMode}
            className="text-sm text-gray-500 hover:text-gray-700 flex items-center gap-2"
          >
            {selectedInputMode === 'text' ? (
              <>
                <AudioLines size={14} />
                åˆ‡æ¢åˆ°è¯­éŸ³æ¨¡å¼
              </>
            ) : (
              <>
                <Keyboard size={14} />
                åˆ‡æ¢åˆ°æ–‡æœ¬æ¨¡å¼
              </>
            )}
          </button>
        </div>
      </div>
    );
  };

  // æ„Ÿè°¢è§†å›¾
  const ThankYouView = () => (
    <div className="min-h-screen bg-gradient-to-b from-green-50 to-white flex flex-col items-center justify-center p-6 md:p-8">
      <div className="bg-white p-8 md:p-12 rounded-2xl shadow-2xl max-w-md text-center border border-gray-100">
        <div className="text-5xl mb-6">ğŸ‰</div>
        <h1 className="text-2xl md:text-3xl font-bold mb-4 text-gray-800">æ„Ÿè°¢æ‚¨çš„å‚ä¸ï¼</h1>
        <p className="text-gray-600 mb-6">
          æ‚¨çš„å®éªŒä¼šè¯å·²æˆåŠŸç»“æŸã€‚æ‰€æœ‰äº¤äº’æ•°æ®å·²ä¿å­˜ï¼Œè¿™å°†ä¸ºæˆ‘ä»¬çš„ç ”ç©¶æä¾›å®è´µçš„ä¿¡æ¯ã€‚
        </p>
        
        <div className="mb-6 md:mb-8 p-4 bg-gray-50 rounded-lg">
          <h3 className="font-bold mb-2 text-gray-700">å®éªŒä¿¡æ¯</h3>
          <div className="text-sm text-gray-600 space-y-1">
            <p>å‚ä¸è€…ï¼š<span className="font-medium">{participantName}</span></p>
            <p>ç”¨æˆ·IDï¼š<code className="text-xs bg-gray-200 px-1 rounded">{userId.substring(0, 8)}...</code></p>
            <p>å®éªŒæ¡ä»¶ï¼š<span className="font-medium">{assignedCondition === 'AI_Model' ? 'AIåŠ©æ‰‹' : 'äººç±»ä¼™ä¼´'}</span></p>
            <p>äº¤äº’æ¨¡å¼ï¼š<span className="font-medium">{selectedInputMode === 'voice' ? 'è¯­éŸ³å¯¹è¯' : 'æ–‡æœ¬å¯¹è¯'}</span></p>
            <p>ä¸“å±æ¨¡å‹ï¼š<span className="font-medium">{assignedVoiceModel?.alias || 'æœªåˆ†é…'}</span></p>
            <p>å¯¹è¯æ¶ˆæ¯ï¼š<span className="font-medium">{logs.length} æ¡</span></p>
          </div>
        </div>
        
        <div className="space-y-3">
          <button 
            onClick={() => {
              // æŸ¥çœ‹æ•°æ®ä»ªè¡¨æ¿ï¼ˆå¯ä»¥åœ¨è¿™é‡Œå®ç°ï¼‰
              alert('æ•°æ®ä»ªè¡¨æ¿åŠŸèƒ½æš‚æœªå®ç°');
            }} 
            className="w-full bg-gradient-to-r from-blue-600 to-purple-600 text-white py-3 rounded-lg font-medium hover:opacity-90 transition-opacity shadow-md"
          >
            æŸ¥çœ‹å®éªŒæ•°æ®
          </button>
          <button 
            onClick={() => {
              setParticipantName('');
              setLogs([]);
              setRecognitionError('');
              setCurrentView('login');
            }} 
            className="w-full border-2 border-gray-300 text-gray-700 py-3 rounded-lg font-medium hover:bg-gray-50 transition-colors"
          >
            å¼€å§‹æ–°ä¼šè¯
          </button>
        </div>
      </div>
    </div>
  );

  // æ•°æ®ä»ªè¡¨æ¿è§†å›¾
  const DashboardView = () => {
    const [statistics, setStatistics] = useState({
      totalMessages: 0,
      avgLatency: 0,
      voiceCount: 0,
      textCount: 0,
    });

    useEffect(() => {
      if (logs.length > 0) {
        const voiceLogs = logs.filter(log => log.inputMode === 'voice');
        const textLogs = logs.filter(log => log.inputMode === 'text');
        const latencies = logs.filter(log => log.latency).map(log => log.latency!);
        const avgLatency = latencies.length > 0 
          ? Math.round(latencies.reduce((a, b) => a + b, 0) / latencies.length) 
          : 0;
        
        setStatistics({
          totalMessages: logs.length,
          avgLatency,
          voiceCount: voiceLogs.length,
          textCount: textLogs.length,
        });
      }
    }, [logs]);

    const chartData = logs
      .filter(log => log.latency)
      .map((log, index) => ({
        name: `æ¶ˆæ¯ ${index + 1}`,
        å»¶è¿Ÿ: log.latency || 0,
      }));

    return (
      <div className="min-h-screen bg-gray-50 p-4 md:p-8">
        <div className="max-w-6xl mx-auto">
          <div className="flex flex-col md:flex-row justify-between items-start md:items-center mb-6 md:mb-8 gap-4">
            <div>
              <h1 className="text-2xl md:text-3xl font-bold text-gray-800">å®éªŒæ•°æ®ä»ªè¡¨æ¿</h1>
              <p className="text-gray-600">ç”¨æˆ·ID: {userId}</p>
              <p className="text-gray-600">ä¸“å±æ¨¡å‹: {assignedVoiceModel?.alias || 'æœªåˆ†é…'}</p>
            </div>
            <div className="flex gap-3">
              <button 
                onClick={() => setCurrentView('login')} 
                className="bg-gradient-to-r from-blue-600 to-blue-700 text-white px-5 md:px-6 py-2 md:py-3 rounded-lg hover:opacity-90 transition-opacity shadow-md"
              >
                è¿”å›é¦–é¡µ
              </button>
            </div>
          </div>
          
          {/* ç»Ÿè®¡æ•°æ®å¡ç‰‡ */}
          <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-4 md:gap-6 mb-6 md:mb-8">
            <div className="bg-white p-4 md:p-6 rounded-xl shadow border border-gray-200">
              <div className="text-sm text-gray-500 mb-2">æ€»æ¶ˆæ¯æ•°</div>
              <div className="text-2xl md:text-3xl font-bold text-blue-600">{statistics.totalMessages}</div>
            </div>
            <div className="bg-white p-4 md:p-6 rounded-xl shadow border border-gray-200">
              <div className="text-sm text-gray-500 mb-2">å¹³å‡å“åº”å»¶è¿Ÿ</div>
              <div className="text-2xl md:text-3xl font-bold text-green-600">{statistics.avgLatency}ms</div>
            </div>
            <div className="bg-white p-4 md:p-6 rounded-xl shadow border border-gray-200">
              <div className="text-sm text-gray-500 mb-2">è¯­éŸ³æ¶ˆæ¯æ•°</div>
              <div className="text-2xl md:text-3xl font-bold text-purple-600">{statistics.voiceCount}</div>
            </div>
            <div className="bg-white p-4 md:p-6 rounded-xl shadow border border-gray-200">
              <div className="text-sm text-gray-500 mb-2">æ–‡æœ¬æ¶ˆæ¯æ•°</div>
              <div className="text-2xl md:text-3xl font-bold text-orange-600">{statistics.textCount}</div>
            </div>
          </div>
          
          {/* å»¶è¿Ÿå›¾è¡¨ */}
          {chartData.length > 0 && (
            <div className="bg-white p-4 md:p-6 rounded-xl shadow border border-gray-200 mb-6 md:mb-8">
              <h3 className="text-lg font-semibold mb-4 text-gray-800">å“åº”å»¶è¿Ÿè¶‹åŠ¿</h3>
              <div className="h-64 md:h-80">
                <ResponsiveContainer width="100%" height="100%">
                  <LineChart data={chartData}>
                    <XAxis dataKey="name" />
                    <YAxis label={{ value: 'å»¶è¿Ÿ (ms)', angle: -90, position: 'insideLeft' }} />
                    <Tooltip />
                    <Line 
                      type="monotone" 
                      dataKey="å»¶è¿Ÿ" 
                      stroke="#3b82f6" 
                      strokeWidth={2} 
                      dot={{ r: 4 }} 
                      activeDot={{ r: 6 }}
                    />
                  </LineChart>
                </ResponsiveContainer>
              </div>
            </div>
          )}
          
          {/* åŸå§‹æ•°æ® */}
          <div className="bg-white p-4 md:p-6 rounded-xl shadow border border-gray-200">
            <h3 className="text-lg font-semibold mb-4 text-gray-800">åŸå§‹äº¤äº’æ•°æ®</h3>
            <div className="h-64 md:h-96 overflow-auto">
              <pre className="text-xs bg-gray-50 p-4 rounded border border-gray-200">
                {JSON.stringify(logs, null, 2)}
              </pre>
            </div>
          </div>
        </div>
      </div>
    );
  };

  return (
    <div className="font-sans text-gray-900">
      {currentView === 'login' && <LoginView />}
      {currentView === 'participant' && <ParticipantView />}
      {currentView === 'thank_you' && <ThankYouView />}
      {currentView === 'admin' && <AdminView />}
      {currentView === 'dashboard' && <DashboardView />}
    </div>
  );
};

export default HCIExperimentPlatform;
